
[{"content":"","date":"23 October 2025","externalUrl":null,"permalink":"/","section":"","summary":"","title":"","type":"page"},{"content":"","date":"23 October 2025","externalUrl":null,"permalink":"/blogs/","section":"","summary":"","title":"","type":"blogs"},{"content":"GitHub Actions is a powerful automation platform that allows you to build, test, and deploy your code directly from your GitHub repository. Whether you\u0026rsquo;re a beginner or an experienced developer, GitHub Actions can save you countless hours by automating repetitive tasks. In this guide, we\u0026rsquo;ll walk through the basics of setting up your first workflow.\nWhat Are GitHub Actions? #\rGitHub Actions are automated workflows that run on GitHub\u0026rsquo;s servers whenever specific events occur in your repository. These events could be a push to a branch, a pull request, or even a scheduled time. Think of it as a virtual assistant that watches your repository and performs tasks automatically.\nInstead of manually running tests or deploying your code, you can define these steps in a file, commit it to your repository, and GitHub will handle the rest. This is especially useful for DevOps teams looking to implement CI/CD pipelines without managing additional infrastructure.\nWhy Should You Use GitHub Actions? #\rNo extra infrastructure needed. GitHub Actions runs on GitHub\u0026rsquo;s servers, so you don\u0026rsquo;t need to set up and maintain separate CI/CD servers.\nEasy integration. Since Actions are built into GitHub, they integrate seamlessly with your repository without complex setup.\nCost-effective. GitHub provides generous free limits for public repositories and reasonable pricing for private ones.\nFlexibility. You can automate almost anything—running tests, building Docker images, deploying to cloud platforms, or sending notifications.\nYour First Workflow #\rLet\u0026rsquo;s create a simple workflow that runs tests whenever you push code to your repository.\nFirst, create a directory structure in your repository:\n.github/workflows/ Inside the .github/workflows directory, create a file named test.yml:\nname: Run Tests on: push: branches: - main pull_request: branches: - main jobs: test: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - name: Set up Python uses: actions/setup-python@v4 with: python-version: \u0026#39;3.11\u0026#39; - name: Install dependencies run: | python -m pip install --upgrade pip pip install pytest - name: Run tests run: pytest Let\u0026rsquo;s break down what this workflow does:\nname: The name displayed on GitHub for this workflow.\non: Defines when the workflow runs. In this case, it runs on push events to the main branch and on pull_request events.\njobs: Contains the tasks you want to execute.\nruns-on: Specifies the machine type to run on. ubuntu-latest is a common choice.\nsteps: Individual commands or actions to execute in order.\nuses: Runs a pre-built action from the GitHub marketplace. Here, we\u0026rsquo;re using actions/checkout@v3 to access your repository code and actions/setup-python@v4 to set up Python.\nrun: Executes shell commands directly.\nCommon Real-World Example: Building and Pushing a Docker Image #\rHere\u0026rsquo;s a more practical example that builds a Docker image and pushes it to a container registry:\nname: Build and Push Docker Image on: push: branches: - main jobs: build: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - name: Set up Docker Buildx uses: docker/setup-buildx-action@v2 - name: Log in to Docker Hub uses: docker/login-action@v2 with: username: ${{ secrets.DOCKER_USERNAME }} password: ${{ secrets.DOCKER_PASSWORD }} - name: Build and push uses: docker/build-push-action@v4 with: context: . push: true tags: ${{ secrets.DOCKER_USERNAME }}/my-app:latest Notice the ${{ secrets.DOCKER_USERNAME }} syntax. This references GitHub Secrets, which store sensitive information like credentials. You can add secrets in your repository settings under \u0026ldquo;Secrets and variables.\u0026rdquo;\nTips for Success #\rStart simple. Begin with basic workflows like running tests or linting your code before moving to complex deployments.\nUse marketplace actions. The GitHub marketplace has thousands of pre-built actions. Instead of writing everything from scratch, leverage existing solutions.\nMonitor logs. When a workflow fails, GitHub shows detailed logs. Always check these logs to understand what went wrong.\nTest locally first. Use tools like act to test your workflows locally before pushing to GitHub, saving time and preventing failed runs.\nConclusion #\rGitHub Actions eliminates the need for external CI/CD tools and makes automation accessible to everyone. By starting with simple workflows and gradually adding complexity, you can automate your entire development pipeline. Whether you\u0026rsquo;re running tests, building containers, or deploying applications, GitHub Actions provides a seamless, integrated solution. Start with the examples above, explore the GitHub marketplace, and soon you\u0026rsquo;ll be automating tasks that once required manual intervention.\n","date":"23 October 2025","externalUrl":null,"permalink":"/blogs/blog1-github-actions/","section":"","summary":"","title":"Getting Started with GitHub Actions","type":"blogs"},{"content":"If you\u0026rsquo;re working with Kubernetes, you\u0026rsquo;ve probably noticed that managing YAML files across different environments can get messy quickly. That\u0026rsquo;s where Helm comes in. Helm is a package manager for Kubernetes that helps you define, install, and manage applications using something called charts. In this guide, we\u0026rsquo;ll walk through creating your first Helm chart step by step.\nWhat is a Helm Chart? #\rA Helm chart is essentially a collection of files that describe Kubernetes resources. Think of it as a template for your application that you can reuse across multiple environments like development, staging, and production. Instead of maintaining separate YAML files for each environment, you create one chart and customize it with different values.\nPrerequisites #\rBefore we start, make sure you have:\nHelm installed on your machine Access to a Kubernetes cluster Basic understanding of Kubernetes concepts like Deployments and Services Step 1: Create Your First Chart #\rCreating a new Helm chart is straightforward. Open your terminal and run:\nhelm create my-first-chart This command generates a directory called my-first-chart with a standard structure. Let\u0026rsquo;s explore what\u0026rsquo;s inside.\nStep 2: Understanding the Chart Structure #\rWhen you navigate into the newly created directory, you\u0026rsquo;ll see several files and folders:\nmy-first-chart/ ├── Chart.yaml ├── values.yaml ├── charts/ └── templates/ ├── deployment.yaml ├── service.yaml ├── _helpers.tpl └── NOTES.txt Here\u0026rsquo;s what each component does:\nChart.yaml: This file contains metadata about your chart like its name, version, and description. It\u0026rsquo;s like the identity card for your Helm chart.\nvalues.yaml: This is where you define default configuration values. These values can be referenced in your templates and easily overridden during installation.\ntemplates/: This directory holds all your Kubernetes manifest files. Helm processes these files through a templating engine before sending them to Kubernetes.\ncharts/: If your chart depends on other charts, they go here.\nStep 3: Customize Chart.yaml #\rOpen the Chart.yaml file and update it with your chart details:\napiVersion: v2 name: my-first-chart description: My very first Helm chart type: application version: 0.1.0 appVersion: \u0026#34;1.0.0\u0026#34; The apiVersion: v2 is used for Helm 3, while type: application indicates this chart deploys an application (as opposed to a library chart).\nStep 4: Define Your Values #\rThe values.yaml file lets you parameterize your templates. Here\u0026rsquo;s a simple example:\nreplicaCount: 2 image: repository: nginx tag: \u0026#34;1.21.0\u0026#34; pullPolicy: IfNotPresent service: type: ClusterIP port: 80 These values will be injected into your templates, making your chart flexible and reusable.\nStep 5: Create Templates #\rNow comes the fun part. Templates are regular Kubernetes YAML files with special template directives. Let\u0026rsquo;s look at a simple deployment template:\napiVersion: apps/v1 kind: Deployment metadata: name: {{ .Release.Name }}-deployment spec: replicas: {{ .Values.replicaCount }} selector: matchLabels: app: {{ .Release.Name }} template: metadata: labels: app: {{ .Release.Name }} spec: containers: - name: {{ .Chart.Name }} image: \u0026#34;{{ .Values.image.repository }}:{{ .Values.image.tag }}\u0026#34; imagePullPolicy: {{ .Values.image.pullPolicy }} ports: - containerPort: 80 Notice the template directives enclosed in double curly braces like {{ .Values.replicaCount }}. These get replaced with actual values from your values.yaml file when you install the chart.\nStep 6: Test Your Chart #\rBefore installing, it\u0026rsquo;s wise to validate your chart. Run this command from your chart directory:\nhelm lint . This checks for errors and formatting issues. To see what Kubernetes manifests will be generated without actually installing anything, use:\nhelm template . You can also do a dry run:\nhelm install --dry-run --debug my-release ./my-first-chart Step 7: Install Your Chart #\rOnce everything looks good, install your chart:\nhelm install my-release ./my-first-chart Here, my-release is the name of your release. Helm will generate all the Kubernetes resources and deploy them to your cluster.\nTo verify the installation:\nhelm list kubectl get all Step 8: Update and Manage Your Release #\rIf you need to make changes, update your chart files and run:\nhelm upgrade my-release ./my-first-chart To roll back to a previous version:\nhelm rollback my-release And when you\u0026rsquo;re done, clean up with:\nhelm uninstall my-release Conclusion #\rCongratulations! You\u0026rsquo;ve just created your first Helm chart. We covered the basic structure of a chart, how to define values and templates, and how to install and manage releases. Helm charts might seem complex at first, but once you understand the basics, they become an invaluable tool for managing Kubernetes applications across multiple environments.\nThe key takeaway is that Helm lets you write your Kubernetes manifests once and reuse them everywhere by simply changing values. This makes your deployments more consistent, maintainable, and less error-prone. As you get more comfortable, you can explore advanced features like chart dependencies, hooks, and custom functions to make your charts even more powerful.\n","date":"23 October 2025","externalUrl":null,"permalink":"/blogs/blog2-first-helm-chart/","section":"","summary":"","title":"How to Create Your First Helm Chart","type":"blogs"},{"content":" Kubernetes is great at managing containers, but getting traffic into and between your pods can feel confusing at first. That\u0026rsquo;s where Services come in. A Service is a stable way to expose your applications and manage how pods talk to each other. Let\u0026rsquo;s break down the different types of services and when to use each one.\nWhat is a Kubernetes Service? #\rBefore diving into types, it helps to understand what a Service actually does. Pods in Kubernetes are temporary—they can be created and destroyed frequently. A Service provides a stable IP address and DNS name that acts as a single entry point to reach a group of pods, even as individual pods come and go.\nThink of it like a load balancer sitting in front of your pods. Requests come to the Service, and it routes them to available pods behind it.\nClusterIP Service #\rClusterIP is the default service type in Kubernetes, and it\u0026rsquo;s the simplest one to understand.\nA ClusterIP service creates an internal IP address that\u0026rsquo;s only accessible from within your Kubernetes cluster. No external traffic can reach it directly. This is perfect for internal communication between your microservices.\nUse cases:\nBackend APIs that only your frontend needs to talk to Database services used by multiple applications Internal tools and monitoring services Microservice-to-microservice communication Example:\napiVersion: v1 kind: Service metadata: name: my-app spec: type: ClusterIP selector: app: my-app ports: - protocol: TCP port: 80 targetPort: 8080 NodePort Service #\rNodePort is the next step up. It exposes your service on a specific port across every node in your cluster. This makes your application accessible from outside the cluster using the node\u0026rsquo;s IP address and the assigned port (usually in the 30000-32767 range).\nUse cases:\nDevelopment and testing environments Temporary external access without setting up a proper ingress Services that need direct port access Non-HTTP protocols that ingress can\u0026rsquo;t handle Example:\napiVersion: v1 kind: Service metadata: name: my-app spec: type: NodePort selector: app: my-app ports: - protocol: TCP port: 80 targetPort: 8080 nodePort: 30080 With this configuration, you could access your app at http://node-ip:30080.\nLoadBalancer Service #\rLoadBalancer is the cloud-native approach. When you create a LoadBalancer service, Kubernetes works with your cloud provider (like AWS, Azure, or Google Cloud) to provision an actual load balancer. This gives you a real external IP address that clients can use.\nUse cases:\nProduction applications that need external access Web applications serving end users APIs that external systems need to call When you need automatic SSL certificate management through your cloud provider Example:\napiVersion: v1 kind: Service metadata: name: my-app spec: type: LoadBalancer selector: app: my-app ports: - protocol: TCP port: 80 targetPort: 8080 ExternalName Service #\rExternalName is the odd one out. It doesn\u0026rsquo;t route to pods at all. Instead, it\u0026rsquo;s a DNS alias that maps a Kubernetes service name to an external DNS name.\nUse cases:\nConnecting to external databases (like managed databases outside your cluster) Integrating with third-party APIs Gradually migrating services from outside Kubernetes into your cluster Abstracting external service locations Example:\napiVersion: v1 kind: Service metadata: name: external-db spec: type: ExternalName externalName: my-database.example.com port: 5432 Now pods inside your cluster can reach it using external-db.default.svc.cluster.local.\nBonus: Ingress (Not Technically a Service) #\rWhile not a service type itself, Ingress is worth mentioning. It\u0026rsquo;s a more advanced way to expose HTTP/HTTPS services to the outside world. Ingress is better than LoadBalancer for most production scenarios because it gives you:\nMultiple applications on the same IP Path-based routing Virtual hosting SSL termination For production web applications, Ingress is usually your best choice over LoadBalancer.\nQuick Comparison #\rService Type Scope Port Range Best For ClusterIP Internal only Any Internal communication NodePort Cluster nodes 30000-32767 Development/testing LoadBalancer External Any Production apps ExternalName External DNS N/A External services Conclusion #\rChoosing the right service type depends on how you want traffic to reach your application. Start with ClusterIP for most of your internal services. Use NodePort during development. For production, prefer LoadBalancer for simple cases or Ingress for more advanced traffic management. And remember ExternalName when you need to reference services outside your cluster. Understanding these options gives you the flexibility to design reliable, scalable Kubernetes applications.\n","date":"23 October 2025","externalUrl":null,"permalink":"/blogs/blog3-k8s-services/","section":"","summary":"","title":"Understanding Kubernetes Services: Types and Use Cases","type":"blogs"},{"content":"This is about me.\n","externalUrl":null,"permalink":"/about/","section":"","summary":"","title":"","type":"page"},{"content":"","externalUrl":null,"permalink":"/videos/videos/","section":"Videos","summary":"","title":"","type":"videos"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":"","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","externalUrl":null,"permalink":"/videos/","section":"Videos","summary":"","title":"Videos","type":"videos"}]