
[{"content":"","date":"23 October 2025","externalUrl":null,"permalink":"/","section":"","summary":"","title":"","type":"page"},{"content":"","date":"23 October 2025","externalUrl":null,"permalink":"/blogs/","section":"","summary":"","title":"","type":"blogs"},{"content":"Container images are the foundation of modern DevOps practices. They package your application with all its dependencies, making deployment consistent across different environments. However, not all container images are created equal. This guide walks you through building container images the right way, starting with the basics and progressing to advanced best practices.\nWhy Container Image Quality Matters #\rBefore diving into the technical details, let\u0026rsquo;s understand why crafting better container images is essential. Poor container images lead to larger deployments, slower pull times, increased storage costs, and potential security vulnerabilities. By following industry best practices, you can create images that are lean, secure, and efficient.\nStarting Simple: Your First Container Image #\rLet\u0026rsquo;s begin with a basic Dockerfile. This is the simplest possible approach to containerizing an application.\nFROM python:3.9 WORKDIR /app COPY . . RUN pip install -r requirements.txt CMD [\u0026#34;python\u0026#34;, \u0026#34;app.py\u0026#34;] What\u0026rsquo;s happening here:\nThe FROM instruction sets the base image. We\u0026rsquo;re using Python 3.9, which comes pre-installed with Python and pip. WORKDIR creates a working directory inside the container. COPY brings your application files into the container. RUN executes the pip install command to install dependencies. Finally, CMD specifies what command runs when the container starts.\nThis works, but it\u0026rsquo;s not optimized. The resulting image is large, and every time you rebuild it, you\u0026rsquo;re installing all dependencies from scratch.\nBuilding Better: Introducing Layer Caching #\rDocker builds images in layers. Each instruction creates a new layer. Understanding this helps you write faster, more efficient Dockerfiles.\nFROM python:3.9 WORKDIR /app COPY requirements.txt . RUN pip install -r requirements.txt COPY . . CMD [\u0026#34;python\u0026#34;, \u0026#34;app.py\u0026#34;] What changed:\nWe separated the COPY instructions. Now we copy requirements.txt first and run pip install before copying the application code. Why? Dependencies change less frequently than application code. By ordering instructions this way, Docker caches the dependency layer. When you rebuild after changing your code, Docker reuses the cached dependency layer instead of reinstalling everything.\nThis simple change can cut build times in half or more.\nGoing Minimal: Using Slim and Alpine Base Images #\rBase images contain the operating system and preinstalled tools. The standard Python image is quite large. Slimmer alternatives exist.\nFROM python:3.9-alpine WORKDIR /app COPY requirements.txt . RUN pip install --no-cache-dir -r requirements.txt COPY . . CMD [\u0026#34;python\u0026#34;, \u0026#34;app.py\u0026#34;] What\u0026rsquo;s new:\nalpine is a minimal Linux distribution. A Python 3.9-alpine image is just a few megabytes, compared to the standard image which is hundreds of megabytes. The --no-cache-dir flag tells pip not to store the cache after installation, reducing image size further.\nTrade-off: Alpine uses musl libc instead of glibc. Some applications built for glibc may not work on Alpine. If you encounter compatibility issues, use python:3.9-slim instead. It\u0026rsquo;s still smaller than the standard image but includes more tools.\nLayering Strategy: Multi-stage Builds #\rMulti-stage builds allow you to use multiple base images in one Dockerfile. This is powerful for reducing final image size, especially for compiled languages.\nFROM python:3.9-alpine AS builder WORKDIR /app COPY requirements.txt . RUN pip install --user --no-cache-dir -r requirements.txt FROM python:3.9-alpine WORKDIR /app COPY --from=builder /root/.local /root/.local ENV PATH=/root/.local/bin:$PATH COPY . . CMD [\u0026#34;python\u0026#34;, \u0026#34;app.py\u0026#34;] What\u0026rsquo;s happening:\nThe first stage is named builder. It installs Python packages into /root/.local using the --user flag. The second stage starts fresh from a clean Alpine image. COPY --from=builder copies only the installed packages from the builder stage, skipping the entire pip cache and build artifacts. We set the PATH environment variable to include the copied packages.\nThe builder stage is discarded after the build completes. Your final image contains only what\u0026rsquo;s necessary to run the application, making it significantly smaller.\nSecurity First: Non-root Users #\rRunning processes as root inside containers is a security risk. A compromised application could potentially affect the host system. Create a dedicated user for your application.\nFROM python:3.9-alpine RUN addgroup -g 1001 appgroup \u0026amp;\u0026amp; \\ adduser -D -u 1001 -G appgroup appuser WORKDIR /app COPY requirements.txt . RUN pip install --no-cache-dir -r requirements.txt COPY --chown=appuser:appgroup . . USER appuser CMD [\u0026#34;python\u0026#34;, \u0026#34;app.py\u0026#34;] What\u0026rsquo;s new:\naddgroup and adduser create a system user and group with specific UIDs and GIDs. --chown=appuser:appgroup ensures the copied files are owned by our non-root user. USER appuser switches to this user before running the command. Now your application runs with minimal privileges.\nReducing Attack Surface: Minimal Dependencies #\rScan your Dockerfile for unnecessary dependencies. Every tool installed is a potential vulnerability.\nFROM python:3.9-alpine RUN apk add --no-cache curl RUN addgroup -g 1001 appgroup \u0026amp;\u0026amp; \\ adduser -D -u 1001 -G appgroup appuser WORKDIR /app COPY requirements.txt . RUN pip install --no-cache-dir -r requirements.txt COPY --chown=appuser:appgroup . . USER appuser HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\ CMD curl -f http://localhost:8000/health || exit 1 CMD [\u0026#34;python\u0026#34;, \u0026#34;app.py\u0026#34;] What\u0026rsquo;s new:\nHEALTHCHECK tells Docker how to verify that your container is still working properly. If the health check fails, Docker can restart the container automatically. This improves reliability in production.\napk add --no-cache curl installs curl for health checks but skips Alpine\u0026rsquo;s package cache, keeping the image lean.\nAdvanced: Reducing Secrets and Build Context #\rSensitive data like API keys should never end up in your image. Use Docker build secrets.\nFROM python:3.9-alpine RUN addgroup -g 1001 appgroup \u0026amp;\u0026amp; \\ adduser -D -u 1001 -G appgroup appuser WORKDIR /app COPY requirements.txt . RUN --mount=type=secret,id=pypi_token \\ pip install --no-cache-dir -r requirements.txt COPY --chown=appuser:appgroup . . USER appuser CMD [\u0026#34;python\u0026#34;, \u0026#34;app.py\u0026#34;] What\u0026rsquo;s new:\nRUN --mount=type=secret mounts a secret file during the build. The secret is available inside that specific RUN command but isn\u0026rsquo;t saved in the image layers. This keeps credentials out of your container images entirely.\nBuild it with:\ndocker build --secret pypi_token=/path/to/token.txt -t myapp . Production-Ready: Complete Best Practices Example #\rHere\u0026rsquo;s a comprehensive Dockerfile incorporating all the principles discussed.\n# Build stage FROM python:3.9-alpine AS builder WORKDIR /build COPY requirements.txt . RUN pip install --user --no-cache-dir -r requirements.txt # Runtime stage FROM python:3.9-alpine ARG VERSION=unknown ARG BUILD_DATE LABEL version=${VERSION} LABEL build.date=${BUILD_DATE} RUN apk add --no-cache curl RUN addgroup -g 1001 appgroup \u0026amp;\u0026amp; \\ adduser -D -u 1001 -G appgroup appuser WORKDIR /app COPY --from=builder /root/.local /root/.local ENV PATH=/root/.local/bin:$PATH \\ PYTHONUNBUFFERED=1 COPY --chown=appuser:appgroup . . USER appuser EXPOSE 8000 HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\ CMD curl -f http://localhost:8000/health || exit 1 CMD [\u0026#34;python\u0026#34;, \u0026#34;app.py\u0026#34;] Key additions:\nARG defines build arguments that you can pass at build time with --build-arg. LABEL adds metadata to your image for tracking versions and build information. EXPOSE documents which ports your application uses (it doesn\u0026rsquo;t actually publish ports, but it documents intent). PYTHONUNBUFFERED=1 ensures Python outputs logs immediately instead of buffering them, which is essential for container logging.\nBuild with:\ndocker build \\ --build-arg VERSION=1.0.0 \\ --build-arg BUILD_DATE=$(date -u +\u0026#39;%Y-%m-%dT%H:%M:%SZ\u0026#39;) \\ -t myapp:1.0.0 . Image Scanning and Validation #\rBefore pushing images to production, always scan them for vulnerabilities.\ndocker scan myapp:1.0.0 Or use Trivy, a popular open-source scanner:\ntrivy image myapp:1.0.0 These tools check for known vulnerabilities in base images and dependencies, helping you catch issues before they reach production.\nKey Takeaways #\rBuilding better container images is a journey, not a destination. Start with the fundamentals: understand layer caching and use appropriate base images. Progress toward security by running as non-root users and removing unnecessary dependencies. Finally, implement advanced techniques like multi-stage builds, secrets management, and image scanning.\nEach optimization might seem small, but together they create images that are faster to build, smaller to distribute, more secure to run, and easier to maintain. As you continue working with containers, these practices will become second nature, allowing you to focus on what matters most: your application.\nStart applying these techniques today, and watch your deployment pipelines become more efficient, secure, and reliable.\n","date":"23 October 2025","externalUrl":null,"permalink":"/blogs/blog5-docker-image-best-practices/","section":"","summary":"","title":"Building Production-Ready Container Images","type":"blogs"},{"content":"Docker has become the foundation of modern application deployment. Whether you\u0026rsquo;re containerizing applications, managing development environments, or orchestrating microservices, knowing the right Docker commands can save you hours of troubleshooting. This comprehensive guide walks you through the most useful Docker commands, starting from the basics and progressing to more advanced operations.\nGetting Started: Basic Commands #\rCheck Docker Installation #\rBefore running any Docker commands, verify that Docker is installed and running on your system.\ndocker --version docker info docker run hello-world The docker --version command displays the installed Docker version, docker info shows system-wide information about Docker, and docker run hello-world confirms that Docker daemon is running properly.\nRunning Your First Container #\rThe most fundamental Docker command is docker run. This command creates and starts a new container from an image.\ndocker run nginx This pulls the nginx image from Docker Hub and runs it. The container will run in the foreground by default. To run it in the background (detached mode), use the -d flag:\ndocker run -d nginx docker run -d --name my-nginx nginx The --name flag assigns a custom name to your container, making it easier to manage.\nListing and Managing Containers #\rSee all running containers:\ndocker ps docker container ls To view all containers, including stopped ones:\ndocker ps -a docker ps -aq The -q flag shows only container IDs, which is useful for scripting and batch operations.\nIntermediate Operations: Working with Containers #\rStarting, Stopping, and Removing Containers #\rStop a running container:\ndocker stop \u0026lt;container_id\u0026gt; docker kill \u0026lt;container_id\u0026gt; The stop command sends a SIGTERM signal followed by SIGKILL after a grace period, while kill immediately sends SIGKILL.\nStart a stopped container:\ndocker start \u0026lt;container_id\u0026gt; docker restart \u0026lt;container_id\u0026gt; Remove a stopped container:\ndocker rm \u0026lt;container_id\u0026gt; docker rm -f \u0026lt;container_id\u0026gt; The -f flag forces removal of running containers.\nRemove all stopped containers at once:\ndocker container prune docker rm $(docker ps -aq) Accessing Container Logs #\rView the output from a container:\ndocker logs \u0026lt;container_id\u0026gt; docker logs --tail 50 \u0026lt;container_id\u0026gt; Follow logs in real-time (like tail -f):\ndocker logs -f \u0026lt;container_id\u0026gt; docker logs -f --since 10m \u0026lt;container_id\u0026gt; The --since flag shows logs from a specific time period, and --tail limits the number of lines displayed.\nExecuting Commands Inside Containers #\rRun a command inside a container:\ndocker exec \u0026lt;container_id\u0026gt; ls -la docker exec \u0026lt;container_id\u0026gt; cat /etc/hosts To access the container\u0026rsquo;s shell interactively:\ndocker exec -it \u0026lt;container_id\u0026gt; /bin/bash docker exec -it \u0026lt;container_id\u0026gt; sh The -i flag keeps STDIN open even if not attached, and -t allocates a pseudo-terminal. Together, -it allows you to interact with the container shell just as if you were SSH\u0026rsquo;d into a remote machine.\nInspecting Containers #\rGet detailed information about a container:\ndocker inspect \u0026lt;container_id\u0026gt; docker inspect --format=\u0026#39;{{.State.Status}}\u0026#39; \u0026lt;container_id\u0026gt; The --format flag allows you to extract specific fields using Go templates. This outputs comprehensive JSON data about the container\u0026rsquo;s configuration, network settings, volumes, and environment variables.\nWorking with Images #\rPulling and Searching Images #\rPull an image from Docker Hub:\ndocker pull ubuntu:22.04 docker pull nginx:latest Search for images on Docker Hub:\ndocker search nginx docker search --filter stars=100 nginx Building Your Own Images #\rCreate a Dockerfile in your project directory:\nFROM ubuntu:22.04 RUN apt-get update \u0026amp;\u0026amp; apt-get install -y python3 COPY . /app WORKDIR /app EXPOSE 8000 CMD [\u0026#34;python3\u0026#34;, \u0026#34;app.py\u0026#34;] Build an image from this Dockerfile:\ndocker build -t my-app:1.0 . docker build -t my-app:1.0 --no-cache . The -t flag tags the image with a name and version. The . specifies the build context (current directory). The --no-cache flag ensures a fresh build without using cached layers.\nListing and Managing Images #\rView all images on your system:\ndocker images docker image ls View image history and layers:\ndocker history \u0026lt;image_id\u0026gt; Remove an image:\ndocker rmi \u0026lt;image_id\u0026gt; docker image rm \u0026lt;image_id\u0026gt; Remove all unused images:\ndocker image prune docker image prune -a The -a flag removes all unused images, not just dangling ones.\nTagging and Pushing Images #\rTag an image for a registry:\ndocker tag my-app:1.0 username/my-app:1.0 docker tag my-app:1.0 myregistry.com/my-app:latest Login to a registry:\ndocker login docker login myregistry.com Push an image to a registry:\ndocker push username/my-app:1.0 This allows you to store images in Docker Hub, private registries, or cloud repositories for sharing and deployment.\nAdvanced Operations #\rPort Mapping and Networking #\rRun a container and expose ports:\ndocker run -d -p 8080:80 nginx docker run -d -p 127.0.0.1:8080:80 nginx This maps port 8080 on your host machine to port 80 inside the container. Now, accessing http://localhost:8080 will reach the nginx container. The second command binds only to localhost for security.\nView port mappings:\ndocker port \u0026lt;container_id\u0026gt; Volume Mounting and Data Persistence #\rMount a directory from your host machine into the container:\ndocker run -d -v /host/path:/container/path nginx docker run -d -v my-volume:/data nginx This creates a persistent connection. Changes made in either location are reflected in the other. Volumes are essential for data persistence and local development workflows.\nCreate and manage named volumes:\ndocker volume create my-volume docker volume ls docker volume inspect my-volume docker volume rm my-volume docker volume prune Copy files between host and container:\ndocker cp myfile.txt \u0026lt;container_id\u0026gt;:/app/ docker cp \u0026lt;container_id\u0026gt;:/app/output.log ./ Running Containers with Environment Variables #\rPass environment variables to a container:\ndocker run -d -e DATABASE_URL=postgres://db:5432 my-app docker run -d --env-file .env my-app Use the -e flag for single variables or --env-file to load multiple variables from a file. This is crucial for configuration management without modifying the container image.\nResource Limits and Constraints #\rLimit container resources:\ndocker run -d --memory=\u0026#34;512m\u0026#34; --cpus=\u0026#34;1.5\u0026#34; nginx docker run -d --memory=\u0026#34;1g\u0026#34; --memory-swap=\u0026#34;2g\u0026#34; nginx These flags prevent containers from consuming all system resources.\nMonitoring Container Performance #\rView real-time resource usage statistics:\ndocker stats docker stats \u0026lt;container_id\u0026gt; docker stats --no-stream The docker stats command shows CPU, memory, network I/O, and disk I/O for running containers. The --no-stream flag displays a single snapshot instead of continuous updates.\nDisplay running processes inside a container:\ndocker top \u0026lt;container_id\u0026gt; docker top \u0026lt;container_id\u0026gt; aux This shows process information similar to the Linux top command, but specific to the container.\nInspecting Filesystem Changes #\rView filesystem changes in a container:\ndocker diff \u0026lt;container_id\u0026gt; This command shows files and directories that have been added (A), modified (C), or deleted (D) since the container was created. It\u0026rsquo;s invaluable for debugging and understanding what changes occurred during runtime.\nSaving and Loading Images #\rSave an image to a tar archive:\ndocker save -o myimage.tar my-app:1.0 docker save my-app:1.0 \u0026gt; myimage.tar Load an image from a tar archive:\ndocker load -i myimage.tar docker load \u0026lt; myimage.tar The save and load commands preserve the entire image with all layers, tags, and metadata.\nExporting and Importing Containers #\rExport a container\u0026rsquo;s filesystem:\ndocker export \u0026lt;container_id\u0026gt; -o mycontainer.tar docker export \u0026lt;container_id\u0026gt; \u0026gt; mycontainer.tar Import a container filesystem as an image:\ndocker import mycontainer.tar my-new-image:1.0 cat mycontainer.tar | docker import - my-new-image:1.0 Unlike save/load, the export/import commands flatten the container into a single layer without history or metadata.\nCreating Images from Containers #\rCommit changes in a container to a new image:\ndocker commit \u0026lt;container_id\u0026gt; my-new-image:1.0 docker commit -m \u0026#34;Added nginx config\u0026#34; -a \u0026#34;John Doe\u0026#34; \u0026lt;container_id\u0026gt; my-new-image:1.0 The -m flag adds a commit message, and -a specifies the author. This is useful for creating images from modified containers, though Dockerfiles are preferred for reproducibility.\nDocker Networking #\rList available networks:\ndocker network ls Create a custom network:\ndocker network create my-network docker network create --driver bridge --subnet 192.168.1.0/24 my-network Connect and disconnect containers from networks:\ndocker network connect my-network \u0026lt;container_id\u0026gt; docker network disconnect my-network \u0026lt;container_id\u0026gt; Inspect network details:\ndocker network inspect my-network Remove networks:\ndocker network rm my-network docker network prune Run containers on specific networks:\ndocker run -d --network my-network --name web nginx docker run -d --network my-network --name db postgres Containers on the same custom network can communicate using container names as hostnames.\nDocker Compose for Multi-Container Applications #\rFor applications requiring multiple services, Docker Compose simplifies orchestration. Create a docker-compose.yml:\nversion: \u0026#39;3\u0026#39; services: web: image: nginx ports: - \u0026#34;8080:80\u0026#34; networks: - app-network depends_on: - db db: image: postgres environment: POSTGRES_PASSWORD: secret networks: - app-network volumes: - db-data:/var/lib/postgresql/data networks: app-network: volumes: db-data: Essential Docker Compose commands:\ndocker-compose up -d docker-compose down docker-compose ps docker-compose logs -f docker-compose exec web bash docker-compose build docker-compose restart docker-compose up --scale web=3 System Maintenance and Cleanup #\rCleaning Up Resources #\rDocker can quickly consume disk space. Clean up unused resources:\ndocker system prune docker system prune -a docker system prune -a --volumes The first command removes all stopped containers, unused networks, and dangling images. The -a flag also removes unused images, and --volumes removes unused volumes.\nView Docker disk usage:\ndocker system df docker system df -v Remove specific resource types:\ndocker container prune docker image prune docker volume prune docker network prune Pausing and Unpausing Containers #\rPause all processes in a container:\ndocker pause \u0026lt;container_id\u0026gt; docker unpause \u0026lt;container_id\u0026gt; This freezes the container without stopping it, useful for temporary resource management.\nRenaming Containers #\rRename a container:\ndocker rename old-name new-name Viewing Events #\rMonitor Docker daemon events in real-time:\ndocker events docker events --since 1h docker events --filter type=container This displays real-time information about container lifecycle events, network changes, and image operations.\nWaiting for Container Exit #\rBlock until a container stops and print its exit code:\ndocker wait \u0026lt;container_id\u0026gt; This is useful in scripts where you need to wait for a container to complete before proceeding.\nQuick Reference Table #\rCommand Category Common Commands Container Lifecycle docker run, docker start, docker stop, docker restart, docker kill, docker rm Container Information docker ps, docker logs, docker top, docker stats, docker inspect, docker diff Image Management docker build, docker pull, docker push, docker images, docker rmi, docker tag Data Management docker volume create, docker volume ls, docker cp, docker commit Networking docker network create, docker network connect, docker network ls, docker network inspect System Maintenance docker system prune, docker system df, docker events Import/Export docker save, docker load, docker export, docker import Conclusion #\rDocker commands follow a logical progression from basic container management to advanced multi-container orchestration. Mastering these commands—from docker run and docker ps for everyday operations to docker exec, docker stats, and docker network for complex workflows—will significantly improve your DevOps efficiency.\nStart with the basic commands like running and listing containers, gradually incorporate intermediate operations such as volume mounting and port mapping into your workflow, and progressively explore advanced features like networking, resource monitoring, and Docker Compose as your needs grow. Understanding commands like docker diff for filesystem inspection, docker top for process monitoring, and docker save/docker load for image portability will give you powerful debugging and deployment capabilities.\nRemember, the Docker documentation and docker \u0026lt;command\u0026gt; --help are always available when you need quick reference material. With this comprehensive cheatsheet at your disposal, you\u0026rsquo;re well-equipped to handle containerized applications efficiently in any DevOps environment. Happy containerizing!\n","date":"23 October 2025","externalUrl":null,"permalink":"/blogs/blog4-docker-cheatsheet/","section":"","summary":"","title":"Docker Cheatsheet: Essential Commands for DevOps Engineers","type":"blogs"},{"content":"GitHub Actions is a powerful automation platform that allows you to build, test, and deploy your code directly from your GitHub repository. Whether you\u0026rsquo;re a beginner or an experienced developer, GitHub Actions can save you countless hours by automating repetitive tasks. In this guide, we\u0026rsquo;ll walk through the basics of setting up your first workflow.\nWhat Are GitHub Actions? #\rGitHub Actions are automated workflows that run on GitHub\u0026rsquo;s servers whenever specific events occur in your repository. These events could be a push to a branch, a pull request, or even a scheduled time. Think of it as a virtual assistant that watches your repository and performs tasks automatically.\nInstead of manually running tests or deploying your code, you can define these steps in a file, commit it to your repository, and GitHub will handle the rest. This is especially useful for DevOps teams looking to implement CI/CD pipelines without managing additional infrastructure.\nWhy Should You Use GitHub Actions? #\rNo extra infrastructure needed. GitHub Actions runs on GitHub\u0026rsquo;s servers, so you don\u0026rsquo;t need to set up and maintain separate CI/CD servers.\nEasy integration. Since Actions are built into GitHub, they integrate seamlessly with your repository without complex setup.\nCost-effective. GitHub provides generous free limits for public repositories and reasonable pricing for private ones.\nFlexibility. You can automate almost anything—running tests, building Docker images, deploying to cloud platforms, or sending notifications.\nYour First Workflow #\rLet\u0026rsquo;s create a simple workflow that runs tests whenever you push code to your repository.\nFirst, create a directory structure in your repository:\n.github/workflows/ Inside the .github/workflows directory, create a file named test.yml:\nname: Run Tests on: push: branches: - main pull_request: branches: - main jobs: test: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - name: Set up Python uses: actions/setup-python@v4 with: python-version: \u0026#39;3.11\u0026#39; - name: Install dependencies run: | python -m pip install --upgrade pip pip install pytest - name: Run tests run: pytest Let\u0026rsquo;s break down what this workflow does:\nname: The name displayed on GitHub for this workflow.\non: Defines when the workflow runs. In this case, it runs on push events to the main branch and on pull_request events.\njobs: Contains the tasks you want to execute.\nruns-on: Specifies the machine type to run on. ubuntu-latest is a common choice.\nsteps: Individual commands or actions to execute in order.\nuses: Runs a pre-built action from the GitHub marketplace. Here, we\u0026rsquo;re using actions/checkout@v3 to access your repository code and actions/setup-python@v4 to set up Python.\nrun: Executes shell commands directly.\nCommon Real-World Example: Building and Pushing a Docker Image #\rHere\u0026rsquo;s a more practical example that builds a Docker image and pushes it to a container registry:\nname: Build and Push Docker Image on: push: branches: - main jobs: build: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - name: Set up Docker Buildx uses: docker/setup-buildx-action@v2 - name: Log in to Docker Hub uses: docker/login-action@v2 with: username: ${{ secrets.DOCKER_USERNAME }} password: ${{ secrets.DOCKER_PASSWORD }} - name: Build and push uses: docker/build-push-action@v4 with: context: . push: true tags: ${{ secrets.DOCKER_USERNAME }}/my-app:latest Notice the ${{ secrets.DOCKER_USERNAME }} syntax. This references GitHub Secrets, which store sensitive information like credentials. You can add secrets in your repository settings under \u0026ldquo;Secrets and variables.\u0026rdquo;\nTips for Success #\rStart simple. Begin with basic workflows like running tests or linting your code before moving to complex deployments.\nUse marketplace actions. The GitHub marketplace has thousands of pre-built actions. Instead of writing everything from scratch, leverage existing solutions.\nMonitor logs. When a workflow fails, GitHub shows detailed logs. Always check these logs to understand what went wrong.\nTest locally first. Use tools like act to test your workflows locally before pushing to GitHub, saving time and preventing failed runs.\nConclusion #\rGitHub Actions eliminates the need for external CI/CD tools and makes automation accessible to everyone. By starting with simple workflows and gradually adding complexity, you can automate your entire development pipeline. Whether you\u0026rsquo;re running tests, building containers, or deploying applications, GitHub Actions provides a seamless, integrated solution. Start with the examples above, explore the GitHub marketplace, and soon you\u0026rsquo;ll be automating tasks that once required manual intervention.\n","date":"23 October 2025","externalUrl":null,"permalink":"/blogs/blog1-github-actions/","section":"","summary":"","title":"Getting Started with GitHub Actions","type":"blogs"},{"content":"If you\u0026rsquo;re working with Kubernetes, you\u0026rsquo;ve probably noticed that managing YAML files across different environments can get messy quickly. That\u0026rsquo;s where Helm comes in. Helm is a package manager for Kubernetes that helps you define, install, and manage applications using something called charts. In this guide, we\u0026rsquo;ll walk through creating your first Helm chart step by step.\nWhat is a Helm Chart? #\rA Helm chart is essentially a collection of files that describe Kubernetes resources. Think of it as a template for your application that you can reuse across multiple environments like development, staging, and production. Instead of maintaining separate YAML files for each environment, you create one chart and customize it with different values.\nPrerequisites #\rBefore we start, make sure you have:\nHelm installed on your machine Access to a Kubernetes cluster Basic understanding of Kubernetes concepts like Deployments and Services Step 1: Create Your First Chart #\rCreating a new Helm chart is straightforward. Open your terminal and run:\nhelm create my-first-chart This command generates a directory called my-first-chart with a standard structure. Let\u0026rsquo;s explore what\u0026rsquo;s inside.\nStep 2: Understanding the Chart Structure #\rWhen you navigate into the newly created directory, you\u0026rsquo;ll see several files and folders:\nmy-first-chart/ ├── Chart.yaml ├── values.yaml ├── charts/ └── templates/ ├── deployment.yaml ├── service.yaml ├── _helpers.tpl └── NOTES.txt Here\u0026rsquo;s what each component does:\nChart.yaml: This file contains metadata about your chart like its name, version, and description. It\u0026rsquo;s like the identity card for your Helm chart.\nvalues.yaml: This is where you define default configuration values. These values can be referenced in your templates and easily overridden during installation.\ntemplates/: This directory holds all your Kubernetes manifest files. Helm processes these files through a templating engine before sending them to Kubernetes.\ncharts/: If your chart depends on other charts, they go here.\nStep 3: Customize Chart.yaml #\rOpen the Chart.yaml file and update it with your chart details:\napiVersion: v2 name: my-first-chart description: My very first Helm chart type: application version: 0.1.0 appVersion: \u0026#34;1.0.0\u0026#34; The apiVersion: v2 is used for Helm 3, while type: application indicates this chart deploys an application (as opposed to a library chart).\nStep 4: Define Your Values #\rThe values.yaml file lets you parameterize your templates. Here\u0026rsquo;s a simple example:\nreplicaCount: 2 image: repository: nginx tag: \u0026#34;1.21.0\u0026#34; pullPolicy: IfNotPresent service: type: ClusterIP port: 80 These values will be injected into your templates, making your chart flexible and reusable.\nStep 5: Create Templates #\rNow comes the fun part. Templates are regular Kubernetes YAML files with special template directives. Let\u0026rsquo;s look at a simple deployment template:\napiVersion: apps/v1 kind: Deployment metadata: name: {{ .Release.Name }}-deployment spec: replicas: {{ .Values.replicaCount }} selector: matchLabels: app: {{ .Release.Name }} template: metadata: labels: app: {{ .Release.Name }} spec: containers: - name: {{ .Chart.Name }} image: \u0026#34;{{ .Values.image.repository }}:{{ .Values.image.tag }}\u0026#34; imagePullPolicy: {{ .Values.image.pullPolicy }} ports: - containerPort: 80 Notice the template directives enclosed in double curly braces like {{ .Values.replicaCount }}. These get replaced with actual values from your values.yaml file when you install the chart.\nStep 6: Test Your Chart #\rBefore installing, it\u0026rsquo;s wise to validate your chart. Run this command from your chart directory:\nhelm lint . This checks for errors and formatting issues. To see what Kubernetes manifests will be generated without actually installing anything, use:\nhelm template . You can also do a dry run:\nhelm install --dry-run --debug my-release ./my-first-chart Step 7: Install Your Chart #\rOnce everything looks good, install your chart:\nhelm install my-release ./my-first-chart Here, my-release is the name of your release. Helm will generate all the Kubernetes resources and deploy them to your cluster.\nTo verify the installation:\nhelm list kubectl get all Step 8: Update and Manage Your Release #\rIf you need to make changes, update your chart files and run:\nhelm upgrade my-release ./my-first-chart To roll back to a previous version:\nhelm rollback my-release And when you\u0026rsquo;re done, clean up with:\nhelm uninstall my-release Conclusion #\rCongratulations! You\u0026rsquo;ve just created your first Helm chart. We covered the basic structure of a chart, how to define values and templates, and how to install and manage releases. Helm charts might seem complex at first, but once you understand the basics, they become an invaluable tool for managing Kubernetes applications across multiple environments.\nThe key takeaway is that Helm lets you write your Kubernetes manifests once and reuse them everywhere by simply changing values. This makes your deployments more consistent, maintainable, and less error-prone. As you get more comfortable, you can explore advanced features like chart dependencies, hooks, and custom functions to make your charts even more powerful.\n","date":"23 October 2025","externalUrl":null,"permalink":"/blogs/blog2-first-helm-chart/","section":"","summary":"","title":"How to Create Your First Helm Chart","type":"blogs"},{"content":" Kubernetes is great at managing containers, but getting traffic into and between your pods can feel confusing at first. That\u0026rsquo;s where Services come in. A Service is a stable way to expose your applications and manage how pods talk to each other. Let\u0026rsquo;s break down the different types of services and when to use each one.\nWhat is a Kubernetes Service? #\rBefore diving into types, it helps to understand what a Service actually does. Pods in Kubernetes are temporary—they can be created and destroyed frequently. A Service provides a stable IP address and DNS name that acts as a single entry point to reach a group of pods, even as individual pods come and go.\nThink of it like a load balancer sitting in front of your pods. Requests come to the Service, and it routes them to available pods behind it.\nClusterIP Service #\rClusterIP is the default service type in Kubernetes, and it\u0026rsquo;s the simplest one to understand.\nA ClusterIP service creates an internal IP address that\u0026rsquo;s only accessible from within your Kubernetes cluster. No external traffic can reach it directly. This is perfect for internal communication between your microservices.\nUse cases:\nBackend APIs that only your frontend needs to talk to Database services used by multiple applications Internal tools and monitoring services Microservice-to-microservice communication Example:\napiVersion: v1 kind: Service metadata: name: my-app spec: type: ClusterIP selector: app: my-app ports: - protocol: TCP port: 80 targetPort: 8080 NodePort Service #\rNodePort is the next step up. It exposes your service on a specific port across every node in your cluster. This makes your application accessible from outside the cluster using the node\u0026rsquo;s IP address and the assigned port (usually in the 30000-32767 range).\nUse cases:\nDevelopment and testing environments Temporary external access without setting up a proper ingress Services that need direct port access Non-HTTP protocols that ingress can\u0026rsquo;t handle Example:\napiVersion: v1 kind: Service metadata: name: my-app spec: type: NodePort selector: app: my-app ports: - protocol: TCP port: 80 targetPort: 8080 nodePort: 30080 With this configuration, you could access your app at http://node-ip:30080.\nLoadBalancer Service #\rLoadBalancer is the cloud-native approach. When you create a LoadBalancer service, Kubernetes works with your cloud provider (like AWS, Azure, or Google Cloud) to provision an actual load balancer. This gives you a real external IP address that clients can use.\nUse cases:\nProduction applications that need external access Web applications serving end users APIs that external systems need to call When you need automatic SSL certificate management through your cloud provider Example:\napiVersion: v1 kind: Service metadata: name: my-app spec: type: LoadBalancer selector: app: my-app ports: - protocol: TCP port: 80 targetPort: 8080 ExternalName Service #\rExternalName is the odd one out. It doesn\u0026rsquo;t route to pods at all. Instead, it\u0026rsquo;s a DNS alias that maps a Kubernetes service name to an external DNS name.\nUse cases:\nConnecting to external databases (like managed databases outside your cluster) Integrating with third-party APIs Gradually migrating services from outside Kubernetes into your cluster Abstracting external service locations Example:\napiVersion: v1 kind: Service metadata: name: external-db spec: type: ExternalName externalName: my-database.example.com port: 5432 Now pods inside your cluster can reach it using external-db.default.svc.cluster.local.\nBonus: Ingress (Not Technically a Service) #\rWhile not a service type itself, Ingress is worth mentioning. It\u0026rsquo;s a more advanced way to expose HTTP/HTTPS services to the outside world. Ingress is better than LoadBalancer for most production scenarios because it gives you:\nMultiple applications on the same IP Path-based routing Virtual hosting SSL termination For production web applications, Ingress is usually your best choice over LoadBalancer.\nQuick Comparison #\rService Type Scope Port Range Best For ClusterIP Internal only Any Internal communication NodePort Cluster nodes 30000-32767 Development/testing LoadBalancer External Any Production apps ExternalName External DNS N/A External services Conclusion #\rChoosing the right service type depends on how you want traffic to reach your application. Start with ClusterIP for most of your internal services. Use NodePort during development. For production, prefer LoadBalancer for simple cases or Ingress for more advanced traffic management. And remember ExternalName when you need to reference services outside your cluster. Understanding these options gives you the flexibility to design reliable, scalable Kubernetes applications.\n","date":"23 October 2025","externalUrl":null,"permalink":"/blogs/blog3-k8s-services/","section":"","summary":"","title":"Understanding Kubernetes Services: Types and Use Cases","type":"blogs"},{"content":"This is about me.\n","externalUrl":null,"permalink":"/about/","section":"","summary":"","title":"","type":"page"},{"content":"","externalUrl":null,"permalink":"/videos/videos/","section":"Videos","summary":"","title":"","type":"videos"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":"","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","externalUrl":null,"permalink":"/videos/","section":"Videos","summary":"","title":"Videos","type":"videos"}]